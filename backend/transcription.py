# Adopted from quickstart guide:https://platform.openai.com/docs/guides/speech-to-text/quickstart
# OPTIONS https://platform.openai.com/docs/api-reference/audio/createSpeech

import os
# from openai import OpenAI
import openai
from dotenv import load_dotenv

load_dotenv()

openai.openai_api_key = os.getenv("OPENAI_API_KEY")

print(openai.openai_api_key)

# Transcribes an existing audio file at the specified filepath using
# OpenAI's Audio API (language X --> language X) - WORKING


def generate_transcription(filepath, *args, **kwargs):
    try:
        audio_file = open(filepath, "rb")

        # parse for params that were optional
        param_language = kwargs['language'] \
            if 'language' in kwargs \
            else 'en'

        param_prompt = kwargs['prompt'] \
            if 'prompt' in kwargs \
            else ''

        param_response_format = kwargs['response_format'] \
            if 'response_format' in kwargs \
            else 'json'

        param_temperature = kwargs['temperature'] \
            if 'temperature' in kwargs \
            else 0

        print(param_prompt)

        # request transcription
        response = openai.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language=param_language,
            prompt=param_prompt,
            response_format=param_response_format,
            temperature=param_temperature
        )

        if param_response_format == 'text':
            return response

        print('RESPONSE:\n', response, '\n')
        print('RESPONSE TEXT:\n', response.text, '\n')
        return response.text

    except FileNotFoundError:
        print("File not found.")

    except Exception as e:
        print("An error occurred:", e)


# Translates an existing audio file at the specified filepath using
# OpenAI's Audio API (language X -> English) - WORKING
def generate_translation(filepath, *args, **kwargs):
    try:
        audio_file = open(filepath, "rb")

        # parse for params that were optional (see full list here:
        # # https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes)
        param_prompt = kwargs['prompt'] \
            if 'prompt' in kwargs \
            else ''

        param_response_format = kwargs['response_format'] \
            if 'response_format' in kwargs \
            else 'json'

        param_temperature = kwargs['temperature'] \
            if 'temperature' in kwargs \
            else 0

        # request translation
        response = openai.audio.translations.create(
            model="whisper-1",
            file=audio_file,
            prompt=param_prompt,
            response_format=param_response_format,
            temperature=param_temperature
        )

        print('RESPONSE:\n', response, '\n')
        print('RESPONSE TEXT:\n', response.text, '\n')

        # Return the response

        if param_response_format == 'text':
            return response

        print('RESPONSE:\n', response, '\n')
        print('RESPONSE TEXT:\n', response.text, '\n')
        return response.text

    except FileNotFoundError:
        print("File not found.")

    except Exception as e:
        print("An error occurred:", e)


# Does "Post-processing" of the original transcript generated by Audio API to
# improve reliability, using the Chat API
def process_transcription(temperature, system_prompt, original_transcript):
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            temperature=temperature,
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": original_transcript  # string
                }
            ]
        )
        return response.choices[0].message.content

    except Exception as e:
        print("An error occurred:", e)


# Transcribes an existing audio file at the specified filepath first
# then does post-processing on initial transcription
def generate_enhanced_transcription(filepath, system_prompt, *args, **kwargs):

    # Get initial transcript
    original_transcript = generate_transcription(filepath, *args, **kwargs)

    # Get corrected transcript
    corrected_text = process_transcription(
        0, system_prompt, original_transcript)

    # Return corrected transcript
    print("CORRECTED TEXT:\n", corrected_text)
    return corrected_text


if __name__ == "__main__":
    # Transcription
    generate_transcription('inputs/en-short.wav')

    # Translation - no enhancements
    generate_translation('inputs/sp-short.wav')

    # 'Complex' translation - no enhancements
    generate_transcription('inputs/en-complex.wav')

    # 'Complex' translation - enhanced using prompt parameter
    generate_transcription('inputs/en-complex.wav',
                           prompt=(
                               'ZenithNex, DynaPulse Max, SonicBlast X, '
                               'CyberLink X7,'
                               'Vectronix V9, NebulaLink Alpha, '
                               'QuantumPulse Matrix, '
                               'FUSION, RAZE, BOLT, QUBE, FLARE'
                           )
                           )
    # 'Complex' translation - enhanced using prompt parameter
    system_prompt = (
        "Your task is to correct any spelling discrepancies in the "
        "transcribed "
        "text. Make sure that the names of the following products are spelled "
        "correctly: ZenithNex, DynaPulse Max, CyberLink X7, Vectronix V9, "
        "SonicBlast X, NebulaLink Alpha, QuantumPulse Matrix, FUSION, RAZE, "
        "BOLT, QUBE, FLARE. Only add necessary punctuation such as periods, "
        "commas, and capitalization, and use only the context provided."
    )
    generate_enhanced_transcription(
        'inputs/en-complex.wav', system_prompt)
